{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "71d2ad3b2737414c0184e52001d3bfd669dd7705f0b48cb8b421db1e3c007459"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"sample.csv\",encoding='ISO-8859-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sample_id                 int64\n",
       "sample_name              object\n",
       "latitude                float64\n",
       "longitude               float64\n",
       "loc_prec                float64\n",
       "qgis_geom                object\n",
       "datum                    object\n",
       "depth                   float64\n",
       "material                 object\n",
       "rock_name                object\n",
       "protolith                object\n",
       "sample_description       object\n",
       "density                 float64\n",
       "comments                 object\n",
       "qap_name                 object\n",
       "sia_scheme               object\n",
       "frost_class1             object\n",
       "frost_class2             object\n",
       "frost_class3             object\n",
       "quartz                  float64\n",
       "feldspar                float64\n",
       "lithics                 float64\n",
       "facies                   object\n",
       "texture                  object\n",
       "p_velocity              float64\n",
       "density_model           float64\n",
       "heat_production         float64\n",
       "heat_production_mass    float64\n",
       "ref_id                    int64\n",
       "iso_id                    int64\n",
       "comp_id                   int64\n",
       "major_id                  int64\n",
       "trace_id                  int64\n",
       "rgroup_id                 int64\n",
       "age_id                    int64\n",
       "method_id                 int64\n",
       "country_id                int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample_df = sample_df.drop(['loc_prec','qgis_geom','datum','depth','material','protolith','sample_description','density','comments','qap_name','sia_scheme','frost_class1','frost_class2','frost_class3','facies','texture','ref_id','method_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sample_id                 int64\n",
       "sample_name              object\n",
       "latitude                float64\n",
       "longitude               float64\n",
       "rock_name                object\n",
       "quartz                  float64\n",
       "feldspar                float64\n",
       "lithics                 float64\n",
       "p_velocity              float64\n",
       "density_model           float64\n",
       "heat_production         float64\n",
       "heat_production_mass    float64\n",
       "iso_id                    int64\n",
       "comp_id                   int64\n",
       "major_id                  int64\n",
       "trace_id                  int64\n",
       "rgroup_id                 int64\n",
       "age_id                    int64\n",
       "country_id                int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "clean_sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/whole_rock_comp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample_df.to_csv('clean_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing rows 0 to 100000...Done.\n",
      "importing rows 100000 to 200000...Done.\n",
      "importing rows 200000 to 300000...Done.\n",
      "importing rows 300000 to 400000...Done.\n",
      "importing rows 400000 to 500000...Done.\n",
      "importing rows 500000 to 600000...Done.\n",
      "importing rows 600000 to 700000...Done.\n",
      "importing rows 700000 to 800000...Done.\n",
      "importing rows 800000 to 900000...Done.\n",
      "importing rows 900000 to 1000000...Done.\n",
      "importing rows 1000000 to 1022092...Done.\n"
     ]
    }
   ],
   "source": [
    "rows_imported = 0\n",
    "for data in pd.read_csv('clean_sample.csv', chunksize=100000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='Sample', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    print(f'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}